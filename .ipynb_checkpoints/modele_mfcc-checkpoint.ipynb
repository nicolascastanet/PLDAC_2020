{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, TimeDistributed, LSTM, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, MaxPooling2D, Flatten, Conv2D, BatchNormalization, Lambda, Reshape\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras import backend\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('database/MFCC_bird.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    features, targets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n",
      "Y_train [1:10] ::\n",
      " [[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "\n",
      "\n",
      "X_train shape :: (6152, 216)\n",
      "Y_train shape :: (6152, 2)\n",
      "X_valid shape :: (1537, 216)\n",
      "Y_valid shape :: (1537, 2)\n",
      "X_test shape :: (1, 216)\n",
      "Y_test shape :: (1, 2)\n",
      "Nombre Total de données:  7690\n",
      "Nombre Total de targets:  7690\n"
     ]
    }
   ],
   "source": [
    "VALID_TAUX = 0.20\n",
    "TEST_TAUX = 0.0001\n",
    "ind = 0\n",
    "\n",
    "## Division des features and targets into: 80% train and 20% validation\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split (features, targets, shuffle = True, test_size = VALID_TAUX)\n",
    "\n",
    "## Division des X_validation and Y_validation into: 60% Validation and 40% test\n",
    "X_valid, X_test, Y_valid, Y_test = train_test_split (X_valid, Y_valid, test_size = TEST_TAUX)\n",
    "\n",
    "\"\"\"\n",
    "## Affichage des valeurs de X_train \n",
    "print(\"X_train [10][100][100] ::\", X_train [10], \"  //    X_train [11][100][100]) ::\", X_train [11])\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "## Affichage des targets avant one hot encoding\n",
    "print(\"Y_test :: \", Y_test[ind])\n",
    "print(\"Y_train [1:10] ::\", Y_train[:10])\n",
    "\n",
    "print()\n",
    "print()\n",
    "\"\"\"\n",
    "\n",
    "## ONE HOT ENCODING\n",
    "from keras.utils import to_categorical\n",
    "Y_train = to_categorical(Y_train, num_classes=2)\n",
    "Y_valid = to_categorical(Y_valid, num_classes=2)\n",
    "Y_test = to_categorical(Y_test, num_classes=2)\n",
    "\n",
    "\n",
    "## Affichage des targets après one hot encoding\n",
    "print(Y_test[ind])\n",
    "print(\"Y_train [1:10] ::\\n\", Y_train[:10])\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "## Affichage des shape\n",
    "print(\"X_train shape ::\",X_train.shape)\n",
    "print(\"Y_train shape ::\",Y_train.shape)\n",
    "print(\"X_valid shape ::\",X_valid.shape)\n",
    "print(\"Y_valid shape ::\",Y_valid.shape)\n",
    "print(\"X_test shape ::\",X_test.shape)\n",
    "print(\"Y_test shape ::\",Y_test.shape)\n",
    "\n",
    "## Vérification du nombre totale de données\n",
    "print(\"Nombre Total de données: \", X_train.shape[0] + X_valid.shape[0] + X_test.shape[0]  )\n",
    "print(\"Nombre Total de targets: \", Y_train.shape[0] + Y_valid.shape[0] + Y_test.shape[0]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_MFCC = np.expand_dims(features, -1)\n",
    "\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "X_valid = np.expand_dims(X_valid, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 216, 128)          768       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 216, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 216, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 27648)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 55298     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 220,162\n",
      "Trainable params: 220,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Tensor(\"activation_12/Softmax:0\", shape=(?, 2), dtype=float32, device=/device:GPU:0)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCH_COUNT = 500\n",
    "L2_regularization = 0.001\n",
    "FILTRE = 5\n",
    "Drop = 0.004\n",
    "\n",
    "ACTIV_Rec = 'sigmoid'\n",
    "ACTIV = 'tanh'\n",
    "\n",
    "\n",
    "\n",
    "model_input = Input(features_MFCC.shape, name='input')\n",
    "\n",
    "#model\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(128, FILTRE,padding='same',input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, FILTRE,padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(128, FILTRE,padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2)) # sortie binaire\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    #loading best weights after training\n",
    "    \n",
    "    model.compile(\n",
    "            loss=root_mean_squared_error,\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    print(model.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6152 samples, validate on 1537 samples\n",
      "Epoch 1/500\n",
      "6152/6152 [==============================] - 46s 7ms/step - loss: 0.4470 - acc: 0.7508 - val_loss: 0.4479 - val_acc: 0.7313\n",
      "Epoch 2/500\n",
      "6152/6152 [==============================] - 44s 7ms/step - loss: 0.4342 - acc: 0.7524 - val_loss: 0.4468 - val_acc: 0.7313\n",
      "Epoch 3/500\n",
      " 128/6152 [..............................] - ETA: 40s - loss: 0.4400 - acc: 0.7500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-59cd59a1b9cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCH_COUNT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCH_COUNT,validation_data=(X_valid, Y_valid), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
